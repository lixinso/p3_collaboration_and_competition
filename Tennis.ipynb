{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n",
      "Total score (averaged over agents) this episode: -0.004999999888241291\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):                                         # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddpg_agent import Agent\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0000-0010\t Max Reward: 0.000\t Moving Average: 0.000\n",
      "Episode 0010-0020\t Max Reward: 0.000\t Moving Average: 0.000\n",
      "Episode 0020-0030\t Max Reward: 0.100\t Moving Average: 0.013\n",
      "Episode 0030-0040\t Max Reward: 0.100\t Moving Average: 0.013\n",
      "Episode 0040-0050\t Max Reward: 0.000\t Moving Average: 0.010\n",
      "Episode 0050-0060\t Max Reward: 0.100\t Moving Average: 0.012\n",
      "Episode 0060-0070\t Max Reward: 0.100\t Moving Average: 0.013\n",
      "Episode 0070-0080\t Max Reward: 0.200\t Moving Average: 0.014\n",
      "Episode 0080-0090\t Max Reward: 0.400\t Moving Average: 0.017\n",
      "Episode 0090-0100\t Max Reward: 0.100\t Moving Average: 0.017\n",
      "Episode 0100-0110\t Max Reward: 0.100\t Moving Average: 0.019\n",
      "Episode 0110-0120\t Max Reward: 0.000\t Moving Average: 0.019\n",
      "Episode 0120-0130\t Max Reward: 0.100\t Moving Average: 0.017\n",
      "Episode 0130-0140\t Max Reward: 0.200\t Moving Average: 0.019\n",
      "Episode 0140-0150\t Max Reward: 0.100\t Moving Average: 0.021\n",
      "Episode 0150-0160\t Max Reward: 0.100\t Moving Average: 0.022\n",
      "Episode 0160-0170\t Max Reward: 0.100\t Moving Average: 0.022\n",
      "Episode 0170-0180\t Max Reward: 0.300\t Moving Average: 0.027\n",
      "Episode 0180-0190\t Max Reward: 0.200\t Moving Average: 0.029\n",
      "Episode 0190-0200\t Max Reward: 0.200\t Moving Average: 0.033\n",
      "Episode 0200-0210\t Max Reward: 0.100\t Moving Average: 0.034\n",
      "Episode 0210-0220\t Max Reward: 0.200\t Moving Average: 0.036\n",
      "Episode 0220-0230\t Max Reward: 0.200\t Moving Average: 0.037\n",
      "Episode 0230-0240\t Max Reward: 0.100\t Moving Average: 0.035\n",
      "Episode 0240-0250\t Max Reward: 0.100\t Moving Average: 0.035\n",
      "Episode 0250-0260\t Max Reward: 0.100\t Moving Average: 0.033\n",
      "Episode 0260-0270\t Max Reward: 0.200\t Moving Average: 0.034\n",
      "Episode 0270-0280\t Max Reward: 0.100\t Moving Average: 0.030\n",
      "Episode 0280-0290\t Max Reward: 0.200\t Moving Average: 0.027\n",
      "Episode 0290-0300\t Max Reward: 0.200\t Moving Average: 0.026\n",
      "Episode 0300-0310\t Max Reward: 0.300\t Moving Average: 0.027\n",
      "Episode 0310-0320\t Max Reward: 0.200\t Moving Average: 0.028\n",
      "Episode 0320-0330\t Max Reward: 0.100\t Moving Average: 0.028\n",
      "Episode 0330-0340\t Max Reward: 0.000\t Moving Average: 0.027\n",
      "Episode 0340-0350\t Max Reward: 0.100\t Moving Average: 0.028\n",
      "Episode 0350-0360\t Max Reward: 0.200\t Moving Average: 0.034\n",
      "Episode 0360-0370\t Max Reward: 0.200\t Moving Average: 0.038\n",
      "Episode 0370-0380\t Max Reward: 0.200\t Moving Average: 0.039\n",
      "Episode 0380-0390\t Max Reward: 0.200\t Moving Average: 0.040\n",
      "Episode 0390-0400\t Max Reward: 0.300\t Moving Average: 0.041\n",
      "Episode 0400-0410\t Max Reward: 0.100\t Moving Average: 0.039\n",
      "Episode 0410-0420\t Max Reward: 0.100\t Moving Average: 0.043\n",
      "Episode 0420-0430\t Max Reward: 0.300\t Moving Average: 0.051\n",
      "Episode 0430-0440\t Max Reward: 0.100\t Moving Average: 0.054\n",
      "Episode 0440-0450\t Max Reward: 0.300\t Moving Average: 0.060\n",
      "Episode 0450-0460\t Max Reward: 0.200\t Moving Average: 0.059\n",
      "Episode 0460-0470\t Max Reward: 0.300\t Moving Average: 0.060\n",
      "Episode 0470-0480\t Max Reward: 0.300\t Moving Average: 0.064\n",
      "Episode 0480-0490\t Max Reward: 0.200\t Moving Average: 0.068\n",
      "Episode 0490-0500\t Max Reward: 0.200\t Moving Average: 0.067\n",
      "Episode 0500-0510\t Max Reward: 0.200\t Moving Average: 0.073\n",
      "Episode 0510-0520\t Max Reward: 0.300\t Moving Average: 0.077\n",
      "Episode 0520-0530\t Max Reward: 0.200\t Moving Average: 0.073\n",
      "Episode 0530-0540\t Max Reward: 0.300\t Moving Average: 0.079\n",
      "Episode 0540-0550\t Max Reward: 0.100\t Moving Average: 0.076\n",
      "Episode 0550-0560\t Max Reward: 0.100\t Moving Average: 0.078\n",
      "Episode 0560-0570\t Max Reward: 0.300\t Moving Average: 0.080\n",
      "Episode 0570-0580\t Max Reward: 0.400\t Moving Average: 0.083\n",
      "Episode 0580-0590\t Max Reward: 0.100\t Moving Average: 0.080\n",
      "Episode 0590-0600\t Max Reward: 0.400\t Moving Average: 0.086\n",
      "Episode 0600-0610\t Max Reward: 0.100\t Moving Average: 0.083\n",
      "Episode 0610-0620\t Max Reward: 0.300\t Moving Average: 0.081\n",
      "Episode 0620-0630\t Max Reward: 0.800\t Moving Average: 0.090\n",
      "Episode 0630-0640\t Max Reward: 0.300\t Moving Average: 0.088\n",
      "Episode 0640-0650\t Max Reward: 0.100\t Moving Average: 0.089\n",
      "Episode 0650-0660\t Max Reward: 0.100\t Moving Average: 0.084\n",
      "Episode 0660-0670\t Max Reward: 0.100\t Moving Average: 0.076\n",
      "Episode 0670-0680\t Max Reward: 0.100\t Moving Average: 0.068\n",
      "Episode 0680-0690\t Max Reward: 0.800\t Moving Average: 0.078\n",
      "Episode 0690-0700\t Max Reward: 0.300\t Moving Average: 0.079\n",
      "Episode 0700-0710\t Max Reward: 0.300\t Moving Average: 0.087\n",
      "Episode 0710-0720\t Max Reward: 0.300\t Moving Average: 0.088\n",
      "Episode 0720-0730\t Max Reward: 0.200\t Moving Average: 0.080\n",
      "Episode 0730-0740\t Max Reward: 0.200\t Moving Average: 0.081\n",
      "Episode 0740-0750\t Max Reward: 0.200\t Moving Average: 0.081\n",
      "Episode 0750-0760\t Max Reward: 0.300\t Moving Average: 0.084\n",
      "Episode 0760-0770\t Max Reward: 0.200\t Moving Average: 0.088\n",
      "Episode 0770-0780\t Max Reward: 0.300\t Moving Average: 0.096\n",
      "Episode 0780-0790\t Max Reward: 0.100\t Moving Average: 0.086\n",
      "Episode 0790-0800\t Max Reward: 0.100\t Moving Average: 0.080\n",
      "Episode 0800-0810\t Max Reward: 0.400\t Moving Average: 0.078\n",
      "Episode 0810-0820\t Max Reward: 0.200\t Moving Average: 0.077\n",
      "Episode 0820-0830\t Max Reward: 0.100\t Moving Average: 0.072\n",
      "Episode 0830-0840\t Max Reward: 0.300\t Moving Average: 0.072\n",
      "Episode 0840-0850\t Max Reward: 0.300\t Moving Average: 0.078\n",
      "Episode 0850-0860\t Max Reward: 0.200\t Moving Average: 0.076\n",
      "Episode 0860-0870\t Max Reward: 0.300\t Moving Average: 0.078\n",
      "Episode 0870-0880\t Max Reward: 0.300\t Moving Average: 0.079\n",
      "Episode 0880-0890\t Max Reward: 0.100\t Moving Average: 0.078\n",
      "Episode 0890-0900\t Max Reward: 0.300\t Moving Average: 0.082\n",
      "Episode 0900-0910\t Max Reward: 0.500\t Moving Average: 0.084\n",
      "Episode 0910-0920\t Max Reward: 0.200\t Moving Average: 0.084\n",
      "Episode 0920-0930\t Max Reward: 0.400\t Moving Average: 0.088\n",
      "Episode 0930-0940\t Max Reward: 0.200\t Moving Average: 0.087\n",
      "Episode 0940-0950\t Max Reward: 0.500\t Moving Average: 0.084\n",
      "Episode 0950-0960\t Max Reward: 0.200\t Moving Average: 0.089\n",
      "Episode 0960-0970\t Max Reward: 0.200\t Moving Average: 0.088\n",
      "Episode 0970-0980\t Max Reward: 0.200\t Moving Average: 0.084\n",
      "Episode 0980-0990\t Max Reward: 0.200\t Moving Average: 0.093\n",
      "Episode 0990-1000\t Max Reward: 0.100\t Moving Average: 0.091\n",
      "Episode 1000-1010\t Max Reward: 0.300\t Moving Average: 0.088\n",
      "Episode 1010-1020\t Max Reward: 0.100\t Moving Average: 0.083\n",
      "Episode 1020-1030\t Max Reward: 0.100\t Moving Average: 0.084\n",
      "Episode 1030-1040\t Max Reward: 0.100\t Moving Average: 0.080\n",
      "Episode 1040-1050\t Max Reward: 0.600\t Moving Average: 0.091\n",
      "Episode 1050-1060\t Max Reward: 0.300\t Moving Average: 0.093\n",
      "Episode 1060-1070\t Max Reward: 0.100\t Moving Average: 0.088\n",
      "Episode 1070-1080\t Max Reward: 0.600\t Moving Average: 0.092\n",
      "Episode 1080-1090\t Max Reward: 0.700\t Moving Average: 0.099\n",
      "Episode 1090-1100\t Max Reward: 0.300\t Moving Average: 0.098\n",
      "Episode 1100-1110\t Max Reward: 0.500\t Moving Average: 0.099\n",
      "Episode 1110-1120\t Max Reward: 1.300\t Moving Average: 0.109\n",
      "Episode 1120-1130\t Max Reward: 0.100\t Moving Average: 0.105\n",
      "Episode 1130-1140\t Max Reward: 0.800\t Moving Average: 0.115\n",
      "Episode 1140-1150\t Max Reward: 0.200\t Moving Average: 0.100\n",
      "Episode 1150-1160\t Max Reward: 0.300\t Moving Average: 0.099\n",
      "Episode 1160-1170\t Max Reward: 0.700\t Moving Average: 0.111\n",
      "Episode 1170-1180\t Max Reward: 0.300\t Moving Average: 0.110\n",
      "Episode 1180-1190\t Max Reward: 1.100\t Moving Average: 0.111\n",
      "Episode 1190-1200\t Max Reward: 0.300\t Moving Average: 0.114\n",
      "Episode 1200-1210\t Max Reward: 0.600\t Moving Average: 0.117\n",
      "Episode 1210-1220\t Max Reward: 0.300\t Moving Average: 0.113\n",
      "Episode 1220-1230\t Max Reward: 0.400\t Moving Average: 0.125\n",
      "Episode 1230-1240\t Max Reward: 0.600\t Moving Average: 0.128\n",
      "Episode 1240-1250\t Max Reward: 0.800\t Moving Average: 0.149\n",
      "Episode 1250-1260\t Max Reward: 0.200\t Moving Average: 0.146\n",
      "Episode 1260-1270\t Max Reward: 0.300\t Moving Average: 0.143\n",
      "Episode 1270-1280\t Max Reward: 0.600\t Moving Average: 0.154\n",
      "Episode 1280-1290\t Max Reward: 0.700\t Moving Average: 0.156\n",
      "Episode 1290-1300\t Max Reward: 0.200\t Moving Average: 0.157\n",
      "Episode 1300-1310\t Max Reward: 0.200\t Moving Average: 0.154\n",
      "Episode 1310-1320\t Max Reward: 0.400\t Moving Average: 0.160\n",
      "Episode 1320-1330\t Max Reward: 0.800\t Moving Average: 0.164\n",
      "Episode 1330-1340\t Max Reward: 0.600\t Moving Average: 0.165\n",
      "Episode 1340-1350\t Max Reward: 0.400\t Moving Average: 0.152\n",
      "Episode 1350-1360\t Max Reward: 0.600\t Moving Average: 0.160\n",
      "Episode 1360-1370\t Max Reward: 0.400\t Moving Average: 0.169\n",
      "Episode 1370-1380\t Max Reward: 0.400\t Moving Average: 0.168\n",
      "Episode 1380-1390\t Max Reward: 1.000\t Moving Average: 0.188\n",
      "Episode 1390-1400\t Max Reward: 0.600\t Moving Average: 0.210\n",
      "Episode 1400-1410\t Max Reward: 1.700\t Moving Average: 0.239\n",
      "Episode 1410-1420\t Max Reward: 0.700\t Moving Average: 0.253\n",
      "Episode 1420-1430\t Max Reward: 5.100\t Moving Average: 0.322\n",
      "Episode 1430-1440\t Max Reward: 0.700\t Moving Average: 0.340\n",
      "Episode 1440-1450\t Max Reward: 0.300\t Moving Average: 0.346\n",
      "Episode 1450-1460\t Max Reward: 0.300\t Moving Average: 0.350\n",
      "Episode 1460-1470\t Max Reward: 0.200\t Moving Average: 0.345\n",
      "Episode 1470-1480\t Max Reward: 1.400\t Moving Average: 0.352\n",
      "Episode 1480-1490\t Max Reward: 1.000\t Moving Average: 0.334\n",
      "Episode 1490-1500\t Max Reward: 3.200\t Moving Average: 0.343\n",
      "Episode 1500-1510\t Max Reward: 1.700\t Moving Average: 0.331\n",
      "Episode 1510-1520\t Max Reward: 0.500\t Moving Average: 0.318\n",
      "Episode 1520-1530\t Max Reward: 0.900\t Moving Average: 0.257\n",
      "Episode 1530-1540\t Max Reward: 3.100\t Moving Average: 0.280\n",
      "Episode 1540-1550\t Max Reward: 1.300\t Moving Average: 0.296\n",
      "Episode 1550-1560\t Max Reward: 0.600\t Moving Average: 0.306\n",
      "Episode 1560-1570\t Max Reward: 1.800\t Moving Average: 0.340\n",
      "Episode 1570-1580\t Max Reward: 0.500\t Moving Average: 0.332\n",
      "Episode 1580-1590\t Max Reward: 2.500\t Moving Average: 0.386\n",
      "Episode 1590-1600\t Max Reward: 5.100\t Moving Average: 0.440\n",
      "Episode 1600-1610\t Max Reward: 1.400\t Moving Average: 0.444\n",
      "Episode 1610-1620\t Max Reward: 1.200\t Moving Average: 0.461\n",
      "Episode 1620-1630\t Max Reward: 0.500\t Moving Average: 0.453\n",
      "Episode 1630-1640\t Max Reward: 1.300\t Moving Average: 0.430\n",
      "Episode 1640-1650\t Max Reward: 1.600\t Moving Average: 0.446\n",
      "Episode 1650-1660\t Max Reward: 0.600\t Moving Average: 0.450\n",
      "Episode 1660-1670\t Max Reward: 0.600\t Moving Average: 0.430\n",
      "Episode 1670-1680\t Max Reward: 0.600\t Moving Average: 0.440\n",
      "Episode 1680-1690\t Max Reward: 0.900\t Moving Average: 0.398\n",
      "Episode 1690-1700\t Max Reward: 5.200\t Moving Average: 0.445\n",
      "<-- Environment Solved in 1608 episodes. \n",
      " Moving Average: 0.518 over past 100 episodes\n",
      "Episode 1700-1710\t Max Reward: 4.400\t Moving Average: 0.538\n",
      "Episode 1710-1720\t Max Reward: 3.200\t Moving Average: 0.595\n",
      "Episode 1720-1730\t Max Reward: 2.000\t Moving Average: 0.617\n",
      "Episode 1730-1740\t Max Reward: 1.400\t Moving Average: 0.639\n",
      "Best episode so far\n",
      " Episode 1742\t Max reward: 5.200 \t Moving average: 0.680\n",
      "Episode 1740-1750\t Max Reward: 5.200\t Moving Average: 0.797\n",
      "Episode 1750-1760\t Max Reward: 4.100\t Moving Average: 0.939\n",
      "Episode 1760-1770\t Max Reward: 5.100\t Moving Average: 1.107\n",
      "Episode 1770-1780\t Max Reward: 3.400\t Moving Average: 1.235\n",
      "Episode 1780-1790\t Max Reward: 5.100\t Moving Average: 1.331\n",
      "Best episode so far\n",
      " Episode 1794\t Max reward: 5.200 \t Moving average: 1.439\n",
      "Episode 1790-1800\t Max Reward: 5.200\t Moving Average: 1.346\n",
      "Best episode so far\n",
      " Episode 1805\t Max reward: 5.200 \t Moving average: 1.425\n",
      "Episode 1800-1810\t Max Reward: 5.200\t Moving Average: 1.343\n",
      "Episode 1810-1820\t Max Reward: 4.000\t Moving Average: 1.415\n",
      "Episode 1820-1830\t Max Reward: 4.200\t Moving Average: 1.492\n",
      "Episode 1830-1840\t Max Reward: 4.400\t Moving Average: 1.571\n",
      "Episode 1840-1850\t Max Reward: 1.600\t Moving Average: 1.416\n",
      "Episode 1850-1860\t Max Reward: 1.600\t Moving Average: 1.314\n",
      "Episode 1860-1870\t Max Reward: 1.000\t Moving Average: 1.156\n",
      "Episode 1870-1880\t Max Reward: 1.400\t Moving Average: 1.058\n",
      "Episode 1880-1890\t Max Reward: 2.400\t Moving Average: 1.024\n",
      "Episode 1890-1900\t Max Reward: 3.400\t Moving Average: 0.988\n",
      "Training stopped. Best score not matched or exceeded for 200 episodes\n"
     ]
    }
   ],
   "source": [
    "SOLVED_SCORE = 0.5\n",
    "CONSEC_EPISODES = 100\n",
    "PRINT_EVERY = 10\n",
    "ADD_NOISE = True\n",
    "\n",
    "def maddpg(n_episodes=2000, max_t=1000, train_mode=True ):\n",
    "    #MADDPG: Multi-Agent Deep Deterministic Policy Gradient\n",
    "    #n_episodes  : maximum number of training episodes\n",
    "    #max_t       : maximum number of timesteps per episode\n",
    "    #train_mode  : set environment to training mode or not\n",
    "    \n",
    "    scores_window = deque(maxlen=CONSEC_EPISODES)\n",
    "    scores_all = []\n",
    "    moving_average = []\n",
    "    best_score = -np.inf\n",
    "    best_episode = 0\n",
    "    already_solved = False\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode = train_mode)[brain_name]\n",
    "        states = np.reshape(env_info.vector_observations, (1, 48))\n",
    "        agent_0.reset()\n",
    "        agent_1.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = get_actions(states, ADD_NOISE)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = np.reshape(env_info.vector_observations, (1,48))\n",
    "            rewards = env_info.rewards\n",
    "            done = env_info.local_done\n",
    "            agent_0.step(states, actions, rewards[0], next_states, done, 0)\n",
    "            agent_1.step(states, actions, rewards[1], next_states, done, 1)\n",
    "            scores += np.max(rewards)\n",
    "            states = next_states\n",
    "            if np.any(done):\n",
    "                break\n",
    "                \n",
    "        ep_best_score = np.max(scores)\n",
    "        scores_window.append(ep_best_score)\n",
    "        scores_all.append(ep_best_score)\n",
    "        moving_average.append(np.mean(scores_window))\n",
    "        \n",
    "        if ep_best_score > best_score:\n",
    "            best_score = ep_best_score\n",
    "            best_episode = i_episode\n",
    "            \n",
    "        if i_episode % PRINT_EVERY == 0:\n",
    "            print(\"Episode {:0>4d}-{:0>4d}\\t Max Reward: {:.3f}\\t Moving Average: {:.3f}\".format(i_episode - PRINT_EVERY, i_episode, np.max(scores_all[-PRINT_EVERY:]), moving_average[-1]))\n",
    "\n",
    "        if moving_average[-1] >= SOLVED_SCORE:\n",
    "            if not already_solved:\n",
    "                print('<-- Environment Solved in {:d} episodes. \\n Moving Average: {:.3f} over past {:d} episodes'.format(i_episode-CONSEC_EPISODES, moving_average[-1], CONSEC_EPISODES))\n",
    "                already_solved = True\n",
    "                torch.save(agent_0.actor_local.state_dict(),  \"models/checkpoint_actor_0.pth\")\n",
    "                torch.save(agent_0.critic_local.state_dict(), \"models/checkpoint_critic_0.pth\")\n",
    "                torch.save(agent_1.actor_local.state_dict(),  \"models/checkpoint_actor_1.pth\")\n",
    "                torch.save(agent_1.critic_local.state_dict(), \"models/checkpoint_critic_1.pth\")\n",
    "            elif ep_best_score >= best_score:\n",
    "                print(\"Best episode so far\\n Episode {:0>4d}\\t Max reward: {:.3f} \\t Moving average: {:.3f}\".format(i_episode, ep_best_score, moving_average[-1]))\n",
    "                torch.save(agent_0.actor_local.state_dict(),  \"models/checkpoint_actor_0.pth\")\n",
    "                torch.save(agent_0.critic_local.state_dict(), \"models/checkpoint_critic_0.pth\")\n",
    "                torch.save(agent_1.actor_local.state_dict(),  \"models/checkpoint_actor_1.pth\")\n",
    "                torch.save(agent_1.critic_local.state_dict(), \"models/checkpoint_critic_1.pth\")\n",
    "            elif (i_episode - best_episode) >= 200:\n",
    "                print(\"Training stopped. Best score not matched or exceeded for 200 episodes\")\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    return scores_all, moving_average\n",
    "\n",
    "def get_actions(states, add_noise):\n",
    "    action_0 = agent_0.act(states, add_noise)\n",
    "    action_1 = agent_1.act(states, add_noise)\n",
    "    return np.concatenate((action_0, action_1), axis=0).flatten()\n",
    "\n",
    "agent_0 = Agent(state_size, action_size, num_agents = 1, random_seed = 0)\n",
    "agent_1 = Agent(state_size, action_size, num_agents = 1, random_seed = 0)\n",
    "\n",
    "scores, avgs = maddpg()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(agent_0.actor_local.state_dict(),  \"models/checkpoint_actor_0.pth\")\n",
    "#torch.save(agent_0.critic_local.state_dict(), \"models/checkpoint_critic_0.pth\")\n",
    "#torch.save(agent_1.actor_local.state_dict(),  \"models/checkpoint_actor_1.pth\")\n",
    "#torch.save(agent_1.critic_local.state_dict(), \"models/checkpoint_critic_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VNXZwPHfyb4RIAs7Iewg+yaiaFGpVeveKlqr1qXu1drXtvq+raKltVpbrS11ad1FsIriAiooKKDsyL6GECAkhCxkX2fmvH/MkpkkM5nJzJ0leb6fDx9muXPvMzfJc8997rnnKK01QgghOr+oUAcghBAiOCThCyFEFyEJXwghughJ+EII0UVIwhdCiC5CEr4QQnQRkvCFEKKLkIQvhBBdhCR8IYToImJCHYCzjIwMnZ2dHeowhBAiYmzZsqVEa53pzbJhlfCzs7PZvHlzqMMQQoiIoZQ64u2yUtIRQoguQhK+EEJ0EZLwhRCiiwirGn5bmpqayM/Pp76+PtShdBkJCQkMGDCA2NjYUIcihAigsE/4+fn5dOvWjezsbJRSoQ6n09NaU1paSn5+PoMHDw51OEKIAAr7kk59fT3p6emS7INEKUV6erqcUQnRCYV9wgck2QeZ7G8hOqewL+kIIYSRck5WUVrdyPQh6a3eW3OwmEFpyWSlJ7X52aOltRwpqyExNppuCbGM7NPN6HD9EhEt/FBTSnHDDTc4nptMJjIzM7nkkktclrv88suZMWOGy2tz586lf//+TJw4keHDh3PVVVexZ88ex/uzZs1i5MiRjB8/nlGjRnHvvfdSXl7ueD86OpqJEycyduxYrr76amprawEoKiriJz/5CUOGDGHKlCnMmDGDDz74wIivL0SnNvtvq5nz0vo237vh5Y2c85dVbj97zl9WccPLG/nxC+v4wbOrjQoxYCTheyE5OZldu3ZRV1cHwIoVK+jfv7/LMuXl5WzdupXy8nIOHz7s8t4DDzzAtm3bOHjwIHPmzOG8886juLjY8f6CBQvYsWMHO3bsID4+nssvv9zxXmJiItu2bWPXrl3ExcXxwgsvoLXmiiuu4JxzziE3N5ctW7awaNEi8vPzDdwLQohIJwnfSxdddBFLly4FYOHChVx33XUu7y9evJhLL72Ua6+9lkWLFrldz5w5c7jgggt4++23W70XFxfHU089xdGjR9m+fXur988++2xycnJYuXIlcXFx3HnnnY73Bg0axC9+8YuOfj0hRBcQUTX8xz7ezZ6CyoCu87R+qTx66Zh2l7v22mt5/PHHueSSS9ixYwe33HILa9ascby/cOFCHn30UXr37s2Pf/xjHn74Ybfrmjx5Mvv27WvzvejoaCZMmMC+ffuYMGGC43WTycSnn37KhRdeyO7du5k8ebIP31KI4KltNPHEsn08dNEokuONSzEWi+ZPy/Zyy8zB9OuRaNh2nOWV1PDO5mP85gcj2Z5fEZRtBpKhLXylVJ5SaqdSaptSKqJHRRs/fjx5eXksXLiQiy++2OW9oqIicnJymDlzJiNGjCAmJoZdu3a5XZfW2uO2nN+vq6tj4sSJTJ06laysLG699dZWy99zzz1MmDCBadOm+fithAi8V7/J4831R3hxda6h29l69BT/WXuYX/13m6HbcXbL65t4/qtDHC2r5Yr53wRtu4ESjBb+uVrrkkCsyJuWuJEuu+wyHnzwQb766itKS0sdr7/zzjucOnXKcaNSZWUlixYtYt68eW2u57vvvmPq1Kltvmc2m9m5cyejR48Gmmv4zsaMGcPixYsdz+fPn09JSYnbdQoRTGaLtcHSXsPGX7bNOLYXDCZz8LZlBKnh++CWW27hkUceYdy4cS6vL1y4kM8++4y8vDzy8vIcF1HbsnjxYpYvX97qGgBYh5F4+OGHGThwIOPHj3cbx3nnnUd9fT3PP/+84zV77x0hhPEMPpYZxugWvgaWK6U08KLW+iWDt2eoAQMGcP/997u8lpeXx9GjRznjjDMcrw0ePJjU1FQ2bNgAwDPPPMNbb71FTU0NY8eOZeXKlWRmNs9XcP311xMfH09DQwOzZ8/mww8/9BiHUoolS5bwwAMP8NRTT5GZmUlycjJPPvlkAL+tEP6J1KToSaTfk2h0wj9La12glOoFrFBK7dNau3RWVUrdDtwOkJWVZXA4HVNdXd3qtVmzZjFr1iwAjh8/3ur9rVu3AjB9+nTmzp3rdt1fffWVz9sG6Nu3r8feQEKIwIv0g5ihJR2tdYHt/5PAB8DpbSzzktZ6qtZ6qnOrVwgR2SK9NdwZGZbwlVLJSqlu9sfABYD7ritCCBHmIv0gZmRJpzfwgW0grhjgba31ZwZuTwgRRiK9/NEZGZbwtda5wIR2FxRCdCrBagQb3e3T47ZDtmX/SLdMIURARWoy7Aok4QshIpLM2+A7Sfgh8sILL/DGG2+EOgwhAq4zp+FI/24RNXhaZ+I80qUQQgSDtPDbkZeXx6hRo7jtttsYO3Ys119/PV988QVnnXUWw4cPZ+PGjQCUlZVxxRVXMH78eM444wx27NiBxWIhOzvbZUKTYcOGUVRUxNy5c3n66acB601cv/3tbzn99NMZMWKEYxTO2tparrnmGsaPH8+cOXOYPn06mze3HoPu8ccfZ9q0aYwdO5bbb78drTV79+7l9NObb3vIy8tzDNewbNkyRo0axcyZM7nvvvtaTeQihOicIquF/8tfwrYAj4w3cSI8+6zHRXJycnj33Xd56aWXmDZtGm+//TZr167lo48+4k9/+hNLlizh0UcfZdKkSSxZsoSVK1dy4403sm3bNi6//HI++OADbr75ZjZs2EB2dja9e/dutQ2TycTGjRtZtmwZjz32GF988QX/+te/6NmzJzt27GDXrl1MnDixzfjuvfdeHnnkEQBuuOEGPvnkEy699FIaGxvJzc1lyJAhvPPOO1xzzTXU19dzxx13sHr1agYPHtzmmD5CiM5JWvheGDx4MOPGjSMqKooxY8Zw/vnno5Ri3Lhx5OXlAbB27VrHNIjnnXcepaWlVFRUMGfOHN555x0AFi1axJw5c9rcxlVXXQXAlClTXNZ57bXXAjB27Fi3A6qtWrWK6dOnM27cOFauXMnu3bsBuOaaa/jvf/8LWEf0nDNnDvv27WPIkCGOkT0l4QvRdURWC7+dlrhR4uPjHY+joqIcz6OiojCZTEDbfYKVUsyYMYOcnByKi4tZsmQJv/vd7zxuIzo62uM6W6qvr+fuu+9m8+bNDBw4kLlz51JfXw9YZ9e6+uqrueqqq1BKMXz4cL777jsfvrkQoi2hvAfAH9LCD5BzzjmHBQsWANYB0TIyMkhNTUUpxZVXXsmvfvUrRo8eTXp6utfrnDlzpqOFvmfPHnbu3NlqGXtyz8jIoLq6mvfee8/x3tChQ4mOjuYPf/iD48xi1KhR5ObmOs4i7GcfQgSaNrhHfiiSbqR3BY2sFn4Ymzt3LjfffDPjx48nKSmJ119/3fHenDlzmDZtGq+99ppP67z77ru56aabGD9+PJMmTWL8+PF0797dZZkePXrw85//nHHjxpGdnd1q1qs5c+bw61//2jGxemJiIv/617+48MILycjIcLmwK4To3CThtyM7O9tlukLnpO38Xlpamttx7KdOndqqNeI8ZLLzEMkZGRmO1ndCQgJvvfUWCQkJHDp0iPPPP59Bgwa1Wv+8efPczq714IMP8uCDD7q8du6557Jv3z601txzzz0yU5YwhDK413qkt7ZDQRJ+GKutreXcc8+lqakJrTXPP/88cXFxfq/33//+N6+//jqNjY1MmjSJO+64IwDRCiHCnST8MNatW7c2+93764EHHuCBBx4I+HqFcNYZa/iObYdsy/6JiIu2kXpFPFLJ/hb+6MyVlkj/amGf8BMSEigtLZUkFCRaa0pLS0lISAh1KCJCBetPNRQ1/EjPQmFf0hkwYAD5+fkUFxeHOpQuIyEhgQEDBoQ6DCFEgIV9wo+NjXXcFSqECH9S0glfYV/SEUKItgS6zJv90FIKK+rcvldV30RuSY1t2+2v7+K/r2Hk7z4NZIh+k4QvhBA2ucU1bt8rrmrwaV17CitpMFn8DSmgJOELISKSERdtPbXcLU7vRWrZShK+EKLL8q0s1LxspHYalIQvhIhIgajhv7PpmA/b83tzIScJXwhhiEhIkLsLKr1eNgK+Trsk4QshAipYN0QZUsP3kNYtkXAEa0fY98MXQkSWSLorvuUxw1Po3n6tJrOFj7cXdDwoA0nCF0IYwuiGfrAPLK6bc7/t+atyePaLg4bH0xFS0hFCGCJoY+oE6f5Xb0f/9LW/fjBJwhdCBFSwBzXzZxhmXyL19gAWzn30JeELIQIqWKUWYy7auldcHb4td28ZnvCVUtFKqe+UUp8YvS0hhDDK7z7Y1f5CYS4YLfz7gb1B2I4QIgwEq6QT7Iu2jebwGhenIwxN+EqpAcAPgf8YuR0hhOgIXw5OzscXT8eaYF1E7gijW/jPAr8BIv/QKIQIK8YMnuY+k5d4UcOfvyonkOEEnGEJXyl1CXBSa72lneVuV0ptVkptllmthBCRwN2x5i+f7w9uID4ysoV/FnCZUioPWAScp5R6q+VCWuuXtNZTtdZTMzMzDQxHCNGZhPKOXo8lnfCt6BiX8LXWD2utB2its4FrgZVa658atT0hRNcUyJp5IA4hYZzvpR++EMIYwWp/+3XjVQezc+SMFuQqKGPpaK2/Ar4KxraEEF1DsO/o7QykhS+EiEihrOFH6qFGEr4QwhDBSooB7ffu5THE02LhfOYhCV8IYYhIqHOH801SRpCEL4SIaP5ctO1qJOELISJSsKc47Awk4QshIlIgLtqGcbndEJLwhRARLRR1eLnTVgghQqCzl2ECSRK+ECIiGTNaZsBXGVYk4QshIlJAavgBiKP1OsO3piMJXwgR0cI5wYYbSfhCCNFFSMIXQhgiWPXwQI6W6W3MnrYpvXSEEF1GsBJeOI9ZE64k4QshAipoLfvO3qXGAJLwhRCGCFpLX2a88pokfCGEISKjhh/O6TnwJOELIQIqkmr4LdfgbZno4fd3+r1tgAufXc3UeSsCsi5vBGWKQyGECLRQ1vC/O1oekPXsO1EVkPV4S1r4QoiIFm43XoVzlUgSvhBCBFA4XxeQhC+EiGh+jZbZ8sYr/0IJe5LwhRCii5CEL4SIaGFXww91AB5IwhdChEx9k5mPtxeEbPstDxYVtU18sacoRNEYT7plCiFC5k/L9vLGuiNkpMQzY2h6h9YRyBmvfrN4BwCb/m82md3iA7becCEtfCFEyBSU1wNQVd/k82eN7A3TZLYYtu5QkoQvhDCE0XPNhu3gaWFcxJeEL4QIS5X1Tcz7ZA8NJrPH5fy5aGvESUK4XUR2ZljCV0olKKU2KqW2K6V2K6UeM2pbQojw42/i+9vyA/xn7WEWbzkeoIiEkRdtG4DztNbVSqlYYK1S6lOt9XoDtymECBP+lnTsdXRzO6Ubo0tHnYlhCV9bC2zVtqextn/ykxGikwvnkkZXZ2gNXykVrZTaBpwEVmitNxi5PSFE1+NXDT+AcTjWGcbHO0MTvtbarLWeCAwATldKjW25jFLqdqXUZqXU5uLiYiPDEUIEQSSVWMI5ORshKL10tNblwFfAhW2895LWeqrWempmZmYwwhFCdCKRdIAJNSN76WQqpXrYHicCs4F9Rm1PCBEeunoNP5y/vdcJXyk1Uyl1s+1xplJqcDsf6QusUkrtADZhreF/0vFQhRCita5+gPGFV710lFKPAlOBkcCrWHvcvAWc5e4zWusdwKQAxCiEiERSaQk73rbwrwQuA2oAtNYFQDejghJCiEgVzheCvU34jbZ+9RpAKZVsXEhCiE4hSInPn4u2Xa0c5G3C/69S6kWgh1Lq58AXwL+NC0sIIYwXyrF06ho9jxFkBK9q+Frrp5VS3wcqsdbxH9FarzA0MiFEZAtSDT9SW+n1TWGY8JVS0cDnWuvZgCR5IYSIUO2WdLTWZqBWKdU9CPEIITqLCKjhGyGcL9p6O3haPbBTKbUCW08dAK31fYZEJYSIfOGVh9sUxrnZEN4m/KW2f0II4VGwW7iRWsMPBW8v2r6ulIoDRthe2q+19n0SSiGEiBAdnUIxnA8/3t5pOwt4HcjD+n0GKqVu0lqvNi40IUQkCtepZtsUzgV3A3hb0vkrcIHWej+AUmoEsBCYYlRgQggRkcL4IOLtjVex9mQPoLU+gHU8HSGEcBHG+a7L87aFv1kp9TLwpu359cAWY0ISQghhBG8T/l3APcB9WGv4q4F/GRWUECLyGVnK/+/mY8z9aLff6/F0MtLRaxHPfXmwYx8MAm8Tfgzwd63138Bx9228YVEJIYQHv3lvh+NxuN14Fc68reF/CSQ6PU/EOoCaEEK0KRJK+V3teoO3CT9Ba11tf2J7nGRMSEII4b1IvfEqFOcl3ib8GqXUZPsTpdRUoM6YkIQQnUGkF1qMjv+6l9YbvIXWvK3h/xJ4VylVgHU/9APmGBaVECJiRVJ7O5RnB/uLqoK+TY8tfKXUNKVUH631JmAU8A5gAj4DDgchPiFEhIn0ln1n1l5J50Wg0fZ4BvC/wHzgFPCSgXEJIYRXSqobQh2CRx0dk8cI7SX8aK11me3xHOAlrfVirfXvgWHGhiaEiETBLpLkltS0v1AILd56PNQhOLSb8JVS9jr/+cBKp/e8rf8LIURY8tQtM1At8x355QFZTyC0l7QXAl8rpUqw9spZA6CUGgZUGBybECIChU8BQ7TkMeFrrf+olPoS6Ass182HvCjgF0YHJ4QQkS6MSvjtl2W01q06i9pGyxRCiFYiq1tmx4zpl8rugsqAxhIM3t54JYQQwmZUn1Svlw2nsX4k4QshDBFO3RE7wlP04ZTEfSEJXwghfPS+D10tw+m4Z1jCV0oNVEqtUkrtVUrtVkrdb9S2hBDhR0XAUJQREGJAGdmX3gT8j9Z6q1KqG7BFKbVCa73HwG0KIURYCaMGvnEtfK11odZ6q+1xFbAX6G/U9oQQ4SUSavjuzkI04VWKCZSg1PCVUtnAJGBDMLYnhAidzlAm+XBb4IZDCKcDh+EJXymVAiwGfqm1btVxVSl1u1Jqs1Jqc3FxsdHhCCEMFk4JrqOe+mx/qEMwhKEJXykVizXZL9Bav9/WMlrrl7TWU7XWUzMzM40MRwghQiB8joBG9tJRwMvAXvvk50KIzq8zlHQ6KyNb+GcBNwDnKaW22f5dbOD2hBAiYAJ1c5U3Ja6ymsb2FwoAw7plaq3XElnDagghAqAz1PCD7VhZLWnJcYZvR+60FUJ0WcEoP3lzAAxWGUwSvhAioIxKXk1mC8fL64xZuYHCadwdSfhCiIjw+yW7OOvPK6msbwp1KD4JpxKXJHwhhCECnehW7T8JQG2DOWDrVB4uMwYq/jDK95LwhRDCSNLCF0J0GhaLZumOQiwW18zmSy3/6wPFEVeq8ZY3NXxPZxqBJAlfCOGXtzce5Z63t7Jw09EOr2PBhqPcs2BrAKMKI9LCF0J0FierGqz/Vza4vO5rKeNwSU2gQvJaULplerGMdMsUQkQEe67Sjudyv6WzcBomWhK+EMIvLVun4dTv/LNdhXx9ILSj8C7ZVgDAf9bkknOyOqSxSMIXQgRGkFqyvhxQ7nxrKze9stHt+0aei8SYTTzz8dOMKzyIxaKZt3QvV87/xsAttk8SvhDCL/YSjpR0XD330VNcuecrPn7jAce+qWowhTQmSfhCCL8EezjkYB1Q/DlhiTU3cfGBb5vXVVsbgIj8JwlfCBEQwbo2GU7XCNxZ9PbDLs9PvvKmy/O1B0tcngfrHgRJ+EIIvzT30gn/RNySEWcnWacKmVKwD5OKYvz9iwDIe2+ZyzJ/XeE6heL9i7YFPpA2SMIXQvglkks6/q5rSGk+P9/wvsvpzVW7VwLw02vnUZmQwo4+w8godp0U3WR2PTgWV7new2AUwyZAEUJ0LZ2tpOPNdl56fx7DyvK5Y+Nivh48mcNp/fnlNwsB2NNrCAAHMgYx+/gOQ2P1lrTwhRB+UW6a+O7S5Xtb8sl+aKnP0/p5ao2/u/kY2Q8t5VQApwo87ZHP210mudE6Pn9GbQU/2r2KB9e8BcDC8RdQmZACQG5af3qcKqZ3lbVun/3QUnYerwhYnL6QhC+ECAhv291vrj8CwJFS16EU2isNeWpx29d5tCy4vWH6Vpe2eu2R2Xfw8EX3OZ6vyxoPwK2bPgxaXO5IwhdCBETLko6v1fFQjEDgz/WHzOpTbb7+xpRLXZ7v7DMMgN7VZR3fWIBIDV+IMFLbaKK20UxGSnyoQ/GaPWn62rXQU343mS0U2KYzzC+rRWvt8wVWk9nieFxV30S3hFifPt+e83M2ALB4zLkMrChiX+ZgXmuR7AFM0THsGTyWy/d+zZrBk3hv3OyAxuELaeELEUYueW4tU+d9EeowOuTtDa7DI1vcZHR3adu5tf3Ep/tYtd86Bs6Lq3N5Y90Rn+O5y2m45TOfWOnz59tz2snDADw2+w6uuf4pHrngLnLTB7S57PZu/QB4etmzJDbWBzwWb0nCFyKM5IZgiGB/tWx5R0VZn1v8qNGsbjHg2aY838shK/YUOR4HekiDCQX7ufG7pQCOi7OePDb7dpaNOBOAcUU5AY3FF5LwhRB+aVkHt+V7L4cF9u6g4LxUOIw2/L9fvQrAK1Mu82r5+tgE5p1/GwDDSo8ZFld7JOELIQIqStlb+AFcqW7zYSt7Cys5VGzsEMTpNeVMP7aLNyddzOOzb/f6cwXdMqmJTWD2wQ0GRueZXLQVQvilZU3eXtIxe9UU9+5CrLc3Wz30/k4A8v78Q6+W74iXFz8GwEejz/Htg0pxMCOLcw5vtZ6mBPsWZaSFL4TwU8u8FW17ob2Sjqe3W77lvGwgZ5Byd9OYW1oz9sQhKuOT2TRgjM/b+2TUTGK0hR71VT5/NhAk4QshAspewze7qel0pGHrmvA7EFSADKwoIkZb+POsn3Xoi9iHW5h8fF+AI/OOJHwhIlBZTSN/W74fS0AL5R3jvpdO4Lah0ZyotHZnfHnt4cCt2EejbV0xd9sSt6/29LZ+7pXFj9O9roqMmrZv3jKKYQlfKfWKUuqkUmqXUdsQoqv6/ZJdPLcyh9UHQztfa1vs6d+fbpktOa/qtW/zArZeXw2ssHb1PNKzb4c+X56Y6ni8/bnr2PzPGwISl7eMbOG/Blxo4PqF6LLqmsyA+7JJMLWsbNjr4u2ffXgfu1Hf0peiTLTFzO9X/oe6mHjKE7p1eJuTf7HA5XmcKTiTn4CBCV9rvRoI/eARQoiQMPt4p20o+FKGH2Br3W/rN8KvHjZlSd151WkIhl+vfr3D6/KV1PCFiGChvID56jeH+d8Pdrp9v70W/uoDJXyxt8jjMnbhcLNVv0pr+ey5M6/ze13zzrvNMRvWzzct4bI9X/m9Tm+EPOErpW5XSm1WSm0uLg6/eqQQ4SgcWsmPfbyHtzccbdW10d5tsr0a/t+/POjD1kKf8YeW5gNwPDXT73WZo6JdhmT40+fzodrYG8YgDBK+1volrfVUrfXUzEz/d6QQIrjcHXyMumgbCuk15cz94kUOpg/kaI8+AVvvddf+kcKUdGbf+jyktD8mj7/kTlshIljo273uOY1O7LdQf88H1i4gRlt4/owfB/QO2XWDJjDjnk5Qw1dKLQTWASOVUvlKqVuN2pYQXU0I7sp3y10sHbkj1mzRZD+0lJyTruWNQN5da7do41Ee+3iPV8uOKcplw4AxvD/2/IDHEUyGtfC11v5f2RBCeGREIvSXPaKOlHSa3JwWGPEtX/0mz7sFtWZS4X4WjznXgCiCK+Q1fCFEZHN3suGuW2ZHhPK4NrrYendtVXxy6IIIEEn4IuCKqxqot90Y5ElVfRPltY1BiCgy1TeZKa5qcPOudzWd0uoGaht9n/wj/5T3k4G7G4AskGcf7a2p2scJTiwW7ZhCsT2nFVkT/uIIL+eAJHxhgGl//IIbX9nY7nKn//FLJj6+IggRRabr/7OBaX/0PN1he4lwyrwvuGL+Nz5t95MdBcx8clWrWad85X7wNPcHK3fHiPYOHrnFvs0UNn9VjtezYI0tyqE2Np7dvTs2fk44kYQvDLHxcPs3Wdd5cRbQlW054n5gLV8u2h4o8q1/97aj5QDsO1Hp1fLuYnGb8D2sy9tx7/31zaESr5cddKqQwz37Y4mKNjCi4JCEL4RwYU+5LUfBdKfVUrYVdKSiE6yhgbz9bmCdkvBwWn8DowkeSfhChEh1g4mvfSibbD9W3qq23tEy+bGyWnbkl7f5nn2dns4ijrupfztfc9iYV+bVtRw7hXJbugnVRdveVSVkVRSxvc/w0AQQYJLwhQiR//nvNm56ZaPXF0gvn/8NM59cBfg/tMLZT63isn+2Xdu3l1U81drP+vPK5idOy135L9d1PvKh96Ojaw8FnUCXerwtif337YcAWD1kckC3HyqS8IUIEfuFxtrG8LqW4Wjhe7m883L5p1xb/nml3vf2AdBu7s5t2cLP7Bbv03o7IrW+mkHlJwDYn5lt+PaCQYZWECJE7K1M/8acCb8brzpKody25INZ0ulTWcLNWz7ijo3vA7Cn1+Dgbdxg0sIXwkBV9U38dfl+TE53kL694SjXvLjOkcQ6ksycSxJtbQPglTamAjxRUc/8VTke122vo3+4vcDxWnWDib8u39/mnbD/WOk66qVz0t54uKxVXG63i3a7L+zTGzbH6NUqXTyxbC8fbjtu3Vdurg6n15TzzQu3OJI9wK8v/qXvGwtT0sIXwkBPfbafN9cfYUhmMldOGgDQagx5f0eVfPrz/by+7gjZ6cn8aIp1G/VNZh7/pPU4Mfe+vZXNHrp7QvM5w/ZjzRd1n/58P699m0dWWhJXTx3osnxRpbubw6w+232CS8b38+KbuN8Xh0ta9rP3fZ+9uDrX4/spDbVs+edPAVg0/gKemHUzFYkdn9kqHEnCF8JA9nsNmjyMM+BPvte6eRsmS3NL2l3irPHiekFbH20wWT/X2IEhML2dhtFa0vGOESWeFz+Y53j80EX3BX4DYUBKOiKgwnEwr3DXoZJOO5dU/fkxtH3ElhN2AAAfA0lEQVSwCM7wnN7GHejfsmElRznryA7WDxzLlHvfCvDaw4ckfBFQkZjvi6sauOQfa1r1La9tNHHF/G/YW+jdHacd9fq6PJ+6L3rDnzKRp096s9rfLnY/7SG47xJ5tKyWS/+xtv0NAGU1nsdguvW1TV6tx252jnUokN9//y5Kk3v49NlIIglfBFQE5nve35rPruOVvP5tnsvrm/JOse1YOX9attfQ7b+3JZ831h3p0Gfd7W+Lm8qLN+30tpJ6lLK/5/tPOMqHcSBaXpxtT3JDLf0rTjqe96ks4dI9X9Pw6eckN9Q6Jh4HiLKY2/5yWnP3uv8CkJMxsPX7nYjU8EVARWJJJ9wj1lq3ugmqvRzqroXvXe5t/Vl/Jlxp+VlfhjVoz6ev/oKsiiK+HjwZpTVnHtlOjLvO/DafjZhBSVIP1meN45PR53DvundIbazlk1Fno1XnbgNLwhcBFayxUALJ3Y1GqsX7oWLREO1jjjT7EbTz2YHFoomKat54OP14B1QUkWVrwX/v8FYACrpl8PmIGZxKTOVXaxe4LF+Ykk7f6lIuPLAOgJ9u+5Svh0xhQuEBAB68+P4gRh8aXTrhT3p8OWcMSef5n04JdSgR4411eTzy4W72Pn4hiXHRZD+0lOtOz+KJq8YBwRvt0Nk7m47y28U72TH3AlITYn3+vCNmBSv2FPHzNzbz7UPnOVqmgfhOz6w4wDVTO1YusJ41tZ3x71/0HVdOch3Y61fvbOP97467vHb1C9/y7p1ntttSv+bFdS4jnVbWNzHx8RWOks4jH+5mSYt1tyeQLXoHrblr/bsAfD78DL4ZNIFdfYaxtf9oxyLPnXktEwoPcDIljbKk7liUYmLBfqK1hVEn85j75UvsfHYOAGsHTaA+NiHwcYaZLp3wT9U28emuE6EOI6K8+LW1L3NpTQMD4pIAWLjxaHPCD0ET8N9rrDcYFZbXk9rH94Rvp1C8s+koALuOV5AU5/+fh31/FFb4Vpt2Lo212WfGlkPb6u7ZMtmD9XqEN1oOa22/kO185rb1aNuDrrmjFHD4MBw7BjNnEm0xMaFgP7npA6iKTya5oZaauESf6kYzju7k+m2fATB39h0Upma2ueHt/Ua6vLRp4FgA1meNJ6v8BLds+QiA3LQBPn2nSNWlE74IvFAkfHuaCMTE3s0jRQamVdrR3jLOH/P3xix/mDo4T2FqfTU/3LeWS/atZtKbp6DgmPWN7t1ZWFHhWK40MZX0OmsvqC+GTuO9cbNZNWQqDbGtx8rJrD7FvOXzGVFyhMGnCgGYds+bFKf07FCML0z/kSPhvz7lkg6tI9JIwu+g4+V19O+RGLD1naioJyMljpho3y4aFZTX0Sc1wbXOqjWFFfX06hZPSXUjfbonuMR8vLwOrTUDeia1Wp/z96qqb8KioXtirMv7nhwvbx4sq7rBREp8+79idY1mymob6Z4Yi8lsoUdSXKtlmswWTtU0kpEST1FVPX27t7/v7ftmT2ElQzNTSIyLprrBRP6pWpLjYhiYlkR5bSM1TjMfNY8F36y9fFvdYHIbt/Mt/OtzSzljSHq7cTvHYd/+noLmrqEVtU1UNzTfQHXwZPMEJ6XV7u96tVg0J1qcadQ0mEj28DMyuevu40GcqYllr/6CAZXFlCR15+DEM+j5s9uJT4yj97FDrNx3krSDu0mrrXTU4AFmH9rE7EPW7pRb+43kuuueoCEmjqGlxxh3IodnP/mry3aWjTizw8ke4GS3dFZnT6JvVQlHevTt8HoiiST8Dvh0ZyF3LdjK67eczvdGtHEq6aPS6gbOeOJLbp05mN9fcprXn8srqWHW01/x6x+M5J5zhzlef3F1Ln/+dB9nD89gzcEStj9yATuOl3PDyxt5/vrJ3LXAeoEr788/dFnf8t0nuP3NLbz6s2mcO6oX4+Yud1lu1f6TeLLmYDE3vNw8teHZT67ku0cuaPd7jH7kM9fv1SIugIff38l7W/K5e9ZQ/vXVIdb85lwGprU+YNkdKa3he3/5inNGZDqm6sv78w85688rqahrcjx3nmJRqeZSilLenzHY19lW3BanhH/tS+uZ/xPfh9ndW1jJlf/61vF8wuPLXd7/zqnEMmWe+ykRn//6ECXVrv3Xxzz6eZtx23m6Q9idKcf3MqCymOXDz+AXl/2Ghpg4MAPVsP2ZB3h14VbWHCxBaQtDSo/TrbGWyvhk+laV0Ku6jGeW/o3JBfsZffIw3z+4nntstXqAj0edzS8vfZAYs4nGmI6X7+xunPMHv9cRSSThd8A228QRewoqA5Lwy20JaNW+kz4lfHtd+OsDxS4Jf+1B6/Rta2z/VzU0sdvWQtx6tLmW27IHxne2sVP2FFZy7qherba3K7+i1WvOnFuhYL1GEiif7rSewq/cZz3oFFbUOxK+PSU5t8TtLdmW87Lak707jha+U7Jvr4XvaZ0tW8jb3Uw60ioOp43mlfo2X6s79t8LXzSavGzha01yYx1nHdnOPz98EoAnZt1sTfZOaptMRNt+57SK4pBTv/fcdGsd/ViP3ry34LcsefN/ADiRksZzZ13Hl0OnUdQtAwBzkKcb/Pu1E7l/0TbD1j9lUMfPVHwhCT+Cxdj66rUcq6RlzVfr5htnnFtsJosmzinh29fj7kYZ17JRcPvcW1rU1tura8d40Y+xZfwK5y6azX1L/Oml4+04MuB6NuD8KW97uRjx42jwIuFHW8x8+e87yS4vdLy2td9Ijvbo0/by7Zw67ew9jH0ZgxhVcoSctAFcdMs/aIr2vzXvjz6pxvbgmZadZuj67bpkwq+oa2LXcc+t1fLaRvYUVnLm0Ay3yxSU17Fo41GG9Uphqu0H9u2hEspqGjlnRGarLoLO6zRbNF/sLaJ/j0SKbXXX3JIaTlbV06tb61+ug0VVLN9TxHWnZ7H/RBXTB6fxxV5r/dO5Tlxe28i3h0pdPrto01GOldXZlm3+A161/yQZKXGkxMfy7uZjHC2z1t+f/GwfV09t3WthndN6tXbtuaG1bmNEQ/c8TXK+I7+c46fqiIuJYubwDHYXVDoGCLMPc/Dy2sOOerg9fSzadJSRvbsxfkCPNg9aaw66tvZb3p5/qrbJMeXg8j0nmJTV3Op6/ds8xvbvjtmi2ZRXRp/UBF5cfcgxAqY7G7yYzN1up9PvpPPUgN4O7bA+t9Tj++vcvP/y2sOUVjcwJDOldUztnJGMKzzIXevfJbu8kMKUdJ449xY+HXmm2wT9k39vaPf3pCE2ngtvnW/9JQvQxXN/Beoifqh1yYR/55tb3P7y2/3s1U1sO1bO/nkXEh/T9unjm+ubb4fP+/MPaTRZ+Mm/NwBw9vAM3rx1usvyN76ykR35FRz840W8/m0e85a2vmX/0n+sZcP/zm71+vefWQ3AXz7fD8Afrxzr6CLp3DK86ZWNrT47f9Uhx+MmU/Oyd7y5pc3vBTC1RS24sr6JtTnNJQGz1i4Hj493FLJo0zG362vpmhfXuX3Peeq9O84Z0uawtiv2FJF/qtblwvOr3+Q1x3PvzFafcb6+AHDv29+5PF+48ajT42Ms3Gj9PqXVjTz60e42Y33ys31uvwdAVb3J5bnFQ4v/8vnN33veJ82/G+0N62u3ZFtB+wu14Q9tDKOcXlPOiJIjvLG0EhJTAejWUMOok4cpS+pOUmM9V+1eyc1bPgZgwcQLeeT7d7VbavGlURAuyR58O1MLZ10y4e8vqmp3GXurymTWeNHRBMBlcoiW9WyAHbYauMmsKShvu192e2OL29lb7OD6y7ijnTOXpg70uoDW3fPMFu1yR2aZh94hLXldFwbyPfQKaplMfbW7wPO+sqtu6Nh22kru7ibeaCm3pLr9hbyQ2FjPBQfX0a+qhMM9+1GUkk72qQIu2beGafl72Jc5iARTIzVxidTEJjC0LJ/02kpSG5oTc07aAPJ69mVa/h66N7gm7NzTv8cVM+6iMqH12UFnUm8Kr2koO6pLJnxftNkPuc3xl7TLsm3NDGTXkTHFW3Jev3PCb6+O29F+1S0vPuoWLfzoKO9bY3U+zOHqaeAt+3dp6xt5M7SAtz8HXw5QzuqaWn9PX/rUx5saGXSqgILUXlTHW89kYs1NDC47TnFyT7LKTxCtLZQndCOlsZaUhlrGFOWS3FRHfUw8P9y3hnFFh9pcd2NUDKboaJSGkqQeDKwookdUNDnpWezqHUdlQjIH07MYVnqMWbmbGVFylL29BvPuuO/Tvb6a4uQenOiWzoybrqBypecZtDqDeoPnHQ7WyYwKp8Gupk6dqjdv3uzXOt5af4TfLdnFH64YS3FVA7edPZi9BZV8e6iU1MRYymsb+UeLX9CstCR+f8lpfP+03uwuqOCt9UddTu8X3Dad6/9jLdWcMSSN9bmt67KXTejH8fI6tthmE0qMjebpqydwz9tb+eH4vtw2c7Cja12vbvGcrPLcIn7n9jM4rV8q4+Yut3UX9Py9Zw7LoKbR5NJFzzBaW2cfVVGgtaM1WBmfDErRva6KiYUHSGyq51iPPozqEcu2asXRHn24avoQcoqrHfvJLtpiZnDZcbo11FKc3IP8Ni74JTTV072+mpHFRxheegyLUmzufxo7+9h6KPn5V5PQVE+c2URmzSmiLBYsUVGk1VbQFB3LqcRu9Kouo1tDLeaoaIpS0uheX01GTTk1cYkkmBoozezPhJkT+M+eCk7rlUReeQO1jWayThUy+FQBKQ21NMTEcaJbOhMKD9CtoZY+VSXEWMwkN9bRFB3DxIID9KkqoT42nl411n1UGxvP2uxJjD2RQ1pdJQkmz0MD29XFxFOa1J1nZ/6ET0ecydCyfNJqKyhMzeRARlZABgq77/zhPPflwfYXDANJcdEdnjD+r1dP4H/e3R7giJrdNWsov71wVIc+q5TaorWe6tWyRiZ8pdSFwN+BaOA/Wus/e1o+EAk/+6GlLs9vnDGIT3YUtjt+Nljr8C0/31Gx0apDfZid/ezMbF5rMWSvz7Sme3012pYME5oaSDQ1MLisgKGlx2iMiaU6LolB5YWk1teQfaqApKZ6yhJTibWY6VVdRn1sPFEWC3HmJuJNjQw+VQBoTnTLILGpwZGYGqNiaIyJJaWx7TKMWUWR17Mv2/qO4FD6QIaW5XNaUS7xpkZ6V5eR3FTvsmxuWn9SGmqxqCjS6ipJNLV9kKyOS0RpTV7PfpQmdSdKWzjaoy9x5iYSTI30qKskxmKm0XYhMdZiIqOmnHhTIwmmRmLNJpKa6ok3B6YbaUN0DNEWC3Wx8URrC0lN7g/uDdGxNEXHUBWXhMJ68KyJTWTF8DMAqIuNZ9CpAsYU5dIQE2cdL6bfKEYW55HaUMOmAWOoi42nW0MN2/uOoCYukT5VpezqPZQTqe47HATKfecN47kIaeF3pGvlbTMHU1TVwOOXjeGaF9fxvRGZvLn+CKP7prLN1o35h+P6stTWbfj1W053XEcbkplMbnENw3qlMH1wGgs2NDci+3VP4NxRvcg5Wc2Gw2Xt3lfiiS8J37CSjlIqGpgPfB/IBzYppT7SWre+QmSgmgazV8m+I2LNTdZkVFtJlDYTrS0kNDWS1FSPRUVhjorCpKKxREVhVlHUxcYTpS0oDdXxSY7TdHdK7XFrTZzZxBBbCy29toI4s4kobSZKa6K1hSiLhShtIcHUSJ+qUoaW5TOs5Bh9qkuJbme4WAALirrYeE6m9KQ6LomMGusvc2lyD5S20BQdQ3V8Io3RsWwcOJba2Hj6VJdiiorhQEYWAD3qq4gzNaGA9VnjKE9IoU9VKdXxSXSvr2ZIaT6ji/M4/9AmfrR7FQDb+g7nYEYW6+OS2DhwDBUJKczO2UC8qYnkxjqq4pMcZYvquESKk3tyKH0gOekD6VVdyhnHdjGkLJ+UhjpSG6rpWVcJKC7Zt4aquCTqY+Ooik+iITqOlMbmu4CP9uhDRUIK9TFxNEXHUBubaFsulsqEFGriEomxmAFNtMVCrNlEYWoGlfHJdK+vplfNKU4m96Q4pSeJTQ2k1lcTb25iZPERBlQUUZzck6SmejJqyokbM5rXYgdRHZdEjMXM1Pw9VMcnsTZ7IidT0lr1VffXrj7DSI6LBjetWfuNVh9uO879i7Yxum8qewsr6ZkUy6f3n8MZT3zpcf2zR/dm27FyStxctxmSkUxuSQ1PXDWOh9/fybTsnrx755k+f4+ymkYm/2FF+wsCXz04i+yM5FavOzfgLp/Yn8sn9nd5LbNbPJv+b3arZe1+Mj3L0Xtpxa++B8Dv2rhXZr7TY3c3sv3xynHtfxGDGVnDPx3I0VrnAiilFgGXA8YmfK0ZdyKHQeWFNMTEMZpeTDtW6yg7mFU0sRbrRbj0mnLSayuI0hbr+/cvZ+7aXGsC1RaUtv6xR2lNFBbiTE0kNtWTaGogq7yIgU63hfvKrKIoSkmjLjaexuhYMmrKUWjiTY1EawvRFgvRWPi72UKUj/3Aa2PjyU0bwKaBp1GS1IOC1F4oW9KvjUukISaWEynp5KYNINZiItpi5mRKGrVxgRsqwiPbTTruBsxaNXSaV6spTunJ7j7D2l8wiD4f0Tqx3TpzMOvWHnY8/65/x07dfeHNb4z92kRibJTjM/ZhODyJjVYet2C/nmMfssJdL7f2JMV5/7lEH5Z11l4RsLN0x7QzMuH3B5z76eUD090s65eDWaOIbbS2NraXF7fqSXCbF+uojY2nalcsl2uFRSksUVFYVBQWFOaoKLSKojE6htrYBOpj4tnabxTLRp6FOSqKgm6ZmKOiMasoW0s4iSiLxZa4zURp6+Okxnq0UpiioulXWULfqmJSG2qIMZs4kDGI+pg4quOTMKsox1mB/bEpKpqjPfpQlJLOqcRu1MUmWONTyrGMRUXRGB3b7plDyClFTRsx9kyKDejdueEiLTmwLXhv9OuRSM5Jzz197MnMPgaQtzcXJcfHkBBrTbBxMa2vA6QkWNOK/aK481hMvohvY93u2OPxVXsHis6V7o1N+G3tq1bNAqXU7cDtAFlZWR3aUEXWEKKarOWPfWkD2Z2exaFxp1NQbeL0wWno8nJ2V0OVCWIsZlJSkyirbSI2LpaDPfpSr6MYPbAnWWlJHC2rZddx1y6Vk7N6+Dwk7Iwh6ewuqKDS1nVwRO8UuifGsu9ElVfdCYdmJjOsVwqf724+ixjQM5H8U+67KfbtnkBZRT0zhqSzMa+sVd/h1IQYRzwAg9KTOFJa67JMt/gYqmwts6GZyRwqbj54np6dxsY86wVr+zg9zsv3SIqlvLaJ3qnxJMRGO9Y9a2QmX+13vekpLjqKqyb3Jz0ljqunDOSTHQXMGtmLS/6xluS4aGqcyhGXT+xHaXWj4z4AewnC2WOXjeHRj3bTt3tCq6GIrzt9ICv3nWyzy+uskZlkpsSTHB9Dg8mC1pol246TEBtNudPBJz4mqtVdp/bSxY0zBrEp7xQF5XVMzurBqv3FjouZt84czFWT+zvun3C3Lvv+65OaQHltk9up/uyD38VGK1ITYpvLfjZ/unIcB09Wccn4fmw/Vs4/V+XQr0cCTSbN/qIqlt13tmPZyyb042BRFXfPGsYzXxzgCtu4+u/ffSb7Cqsor2tk4+EynrhqHI9+uJvhvVMwWTR3f28Yp2obWbqzkNvOHsz+omo+3m69B+DBC0bwoykDWLTxGLefPYSqehM/P3tIm9+lPUopHrnkNJrMFvr2SCS3uJqstCT2Flay5mAJt58zhDUHSxjZp5vbg8qvfzCSv3y+n09+0Xxfxts/n05RZT0F5fVcMr550LSP7j2LdYdKKapsYGNeKUmxMQzoGaSz3iAx7KKtUmoGMFdr/QPb84cBtNZPuPtMIC7aCiFEV+LLRVsjJ3DcBAxXSg1WSsUB1wIfGbg9IYQQHhhW0tFam5RS9wKfY+2W+YrWuu3704UQQhjO0DtttdbLgGVGbkMIIYR3jCzpCCGECCOS8IUQoouQhC+EEF2EJHwhhOgiJOELIUQXEVbDIyulioEj7S7YtgzA91mag0fi84/E5x+Jzz/hHN8grXWmNwuGVcL3h1Jqs7d3m4WCxOcfic8/Ep9/wj0+b0lJRwghughJ+EII0UV0poT/UqgDaIfE5x+Jzz8Sn3/CPT6vdJoavhBCCM86UwtfCCGEBxGf8JVSFyql9iulcpRSD4UohoFKqVVKqb1Kqd1Kqfttr89VSh1XSm2z/bvY6TMP22Ler5T6QRBizFNK7bTFsdn2WppSaoVS6qDt/56215VS6jlbfDuUUpMNjm2k0z7appSqVEr9MtT7Tyn1ilLqpFJql9NrPu8zpdRNtuUPKqVuMji+vyil9tli+EAp1cP2erZSqs5pX77g9Jkptt+NHNt3CMhET27i8/lnatTfuJv43nGKLU8ptc32etD3nyG01hH7D+uwy4eAIUAcsB04LQRx9AUm2x53Aw4ApwFzgQfbWP40W6zxwGDbd4g2OMY8IKPFa08BD9kePwQ8aXt8MfAp1lnLzgA2BPlnegIYFOr9B5wDTAZ2dXSfAWlAru3/nrbHPQ2M7wIgxvb4Saf4sp2Xa7GejcAMW+yfAhcZGJ9PP1Mj/8bbiq/F+38FHgnV/jPiX6S38B0TpWutGwH7ROlBpbUu1FpvtT2uAvZindPXncuBRVrrBq31YSAH63cJtsuB122PXweucHr9DW21HuihlOrb1goMcD5wSGvt6Qa8oOw/rfVqoKyNbfuyz34ArNBal2mtTwErgAuNik9rvVxrbZ/Hcj0wwNM6bDGmaq3XaWv2esPpOwU8Pg/c/UwN+xv3FJ+tlX4NsNDTOozcf0aI9ITf1kTpnhKt4ZRS2cAkYIPtpXttp9ev2E//CU3cGliulNqirPMIA/TWWheC9aAF9AphfHbX4vpHFi77z87XfRbKWG/B2uK0G6yU+k4p9bVSyj65bX9bTMGMz5efaaj239lAkdb6oNNr4bL/OizSE75XE6UHi1IqBVgM/FJrXQk8DwwFJgKFWE8RITRxn6W1ngxcBNyjlDrHw7Ih2a/KOhXmZcC7tpfCaf+1x11ModqX/weYgAW2lwqBLK31JOBXwNtKqdQQxOfrzzRUP+vrcG14hMv+80ukJ/x8YKDT8wFAQSgCUUrFYk32C7TW7wNorYu01mattQX4N81lh6DHrbUusP1/EvjAFkuRvVRj+/9kqOKzuQjYqrUussUaNvvPia/7LOix2i4MXwJcbyszYCuVlNoeb8FaFx9hi8+57GNofB34mYZi/8UAVwHvOMUdFvvPX5Ge8MNionRbve9lYK/W+m9OrzvXva8E7L0BPgKuVUrFK6UGA8OxXvgxKr5kpVQ3+2OsF/Z22eKw9xq5CfjQKb4bbT1PzgAq7GUMg7m0qsJl/7Xg6z77HLhAKdXTVr64wPaaIZRSFwK/BS7TWtc6vZ6plIq2PR6CdZ/l2mKsUkqdYfs9vtHpOxkRn68/01D8jc8G9mmtHaWacNl/fgv1VWN//2HtHXEA6xH3/0IUw0ysp3E7gG22fxcDbwI7ba9/BPR1+sz/2WLej8FX9bH2cNhu+7fbvp+AdOBL4KDt/zTb6wqYb4tvJzA1CPswCSgFuju9FtL9h/XgUwg0YW3J3dqRfYa1lp5j+3ezwfHlYK15238PX7At+yPbz347sBW41Gk9U7Em3kPAP7HdkGlQfD7/TI36G28rPtvrrwF3tlg26PvPiH9yp60QQnQRkV7SEUII4SVJ+EII0UVIwhdCiC5CEr4QQnQRkvCFEKKLkIQvOgWllFm5jrjpcVRFpdSdSqkbA7DdPKVURgc+9wNlHTmyp1Jqmb9xCOGNmFAHIESA1GmtJ3q7sNb6hfaXMtTZwCqsIzZ+E+JYRBchCV90akqpPKy3yJ9re+knWuscpdRcoFpr/bRS6j7gTqxjz+zRWl+rlEoDXsF601otcLvWeodSKh3rDTuZWO8EVU7b+ilwH9ZhfDcAd2utzS3imQM8bFvv5UBvoFIpNV1rfZkR+0AIOynpiM4isUVJZ47Te5Va69Ox3gX5bBuffQiYpLUejzXxAzwGfGd77X+xDnsL8CiwVlsH0foIyAJQSo0G5mAdpG4iYAaub7khrfU7NI/BPg7rHZqTJNmLYJAWvugsPJV0Fjr9/0wb7+8AFiillgBLbK/NxHo7PVrrlUqpdKVUd6wlmKtsry9VSp2yLX8+MAXYZJvwKJHmgdVaGo71NnyAJG2dQ0EIw0nCF12BdvPY7odYE/llwO+VUmPwPOxtW+tQwOta64c9BaKs00tmADFKqT1AX2WdRu8XWus1nr+GEP6Rko7oCuY4/b/O+Q2lVBQwUGu9CvgN0ANIAVZjK8kopWYBJdo6x4Hz6xdhnbYQrAOp/Vgp1cv2XppSalDLQLTWU4GlWOv3T2EdDGyiJHsRDNLCF51Foq2lbPeZ1treNTNeKbUBawPnuhafiwbespVrFPCM1rrcdlH3VaXUDqwXbe1DIj8GLFRKbQW+Bo4CaK33KKV+h3VWsSisIzDeA7Q1VeNkrBd37wb+1sb7QhhCRssUnZqtl85UrXVJqGMRItSkpCOEEF2EtPCFEKKLkBa+EEJ0EZLwhRCii5CEL4QQXYQkfCGE6CIk4QshRBchCV8IIbqI/wcCG1A1SHw2RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89ddb7ff60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, label=\"MADDPG\")\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='moving avg')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
